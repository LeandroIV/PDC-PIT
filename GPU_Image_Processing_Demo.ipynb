{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU-Accelerated Image Processing Demo\n",
    "\n",
    "This notebook demonstrates GPU acceleration for image processing tasks including:\n",
    "- Gaussian blur\n",
    "- Edge detection\n",
    "- Image resizing\n",
    "\n",
    "Make sure to enable GPU runtime for this notebook:\n",
    "- Click \"Runtime\" > \"Change runtime type\"\n",
    "- Select \"GPU\" under Hardware accelerator\n",
    "- Click \"Save\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Install required packages\n",
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import urllib.request\n",
    "from PIL import Image\n",
    "\n",
    "# Check GPU availability\n",
    "print(\"=== GPU AVAILABILITY CHECK ===\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(f\"✅ GPU is available: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory allocated: {torch.cuda.memory_allocated(0) / 1024**2:.2f} MB\")\n",
    "    print(f\"Memory reserved: {torch.cuda.memory_reserved(0) / 1024**2:.2f} MB\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"❌ No GPU available. Running on CPU only.\")\n",
    "    print(\"Note: To enable GPU, go to Runtime > Change runtime type > Hardware accelerator > GPU\")\n",
    "\n",
    "def print_separator():\n",
    "    print(\"\\n\" + \"=\"*70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and Load Sample Image\n",
    "\n",
    "First, let's download a sample image to use for our processing tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def download_sample_image():\n",
    "    \"\"\"Download a sample image if not already present.\"\"\"\n",
    "    image_path = \"sample_image.jpg\"\n",
    "    if not os.path.exists(image_path):\n",
    "        print(\"Downloading sample image...\")\n",
    "        url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/e/e7/Everest_North_Face_toward_Base_Camp_Tibet_Luca_Galuzzi_2006.jpg/1280px-Everest_North_Face_toward_Base_Camp_Tibet_Luca_Galuzzi_2006.jpg\"\n",
    "        urllib.request.urlretrieve(url, image_path)\n",
    "        print(f\"Image downloaded to {image_path}\")\n",
    "    return image_path\n",
    "\n",
    "def load_image(path):\n",
    "    \"\"\"Load an image and convert to PyTorch tensor.\"\"\"\n",
    "    # Read image with OpenCV\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "    \n",
    "    # Convert to PyTorch tensor\n",
    "    img_tensor = torch.from_numpy(img).float().permute(2, 0, 1) / 255.0  # Normalize to [0, 1]\n",
    "    \n",
    "    return img, img_tensor\n",
    "\n",
    "# Download and load the image\n",
    "image_path = download_sample_image()\n",
    "img_np, img_tensor = load_image(image_path)\n",
    "\n",
    "# Display the image\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(img_np)\n",
    "plt.title(\"Sample Image\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Image loaded: {image_path}\")\n",
    "print(f\"Image shape: {img_np.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Gaussian Blur\n",
    "\n",
    "Let's implement Gaussian blur on both CPU and GPU and compare the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def gaussian_blur_cpu(img_tensor, kernel_size=15, sigma=5.0):\n",
    "    \"\"\"Apply Gaussian blur using CPU.\"\"\"\n",
    "    # Convert to numpy for OpenCV\n",
    "    img_np = (img_tensor.permute(1, 2, 0).numpy() * 255.0).astype(np.uint8)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    blurred = cv2.GaussianBlur(img_np, (kernel_size, kernel_size), sigma)\n",
    "    cpu_time = time.time() - start_time\n",
    "    \n",
    "    # Convert back to tensor\n",
    "    result = torch.from_numpy(blurred).float().permute(2, 0, 1) / 255.0\n",
    "    \n",
    "    return result, cpu_time\n",
    "\n",
    "def gaussian_blur_gpu(img_tensor, kernel_size=15, sigma=5.0):\n",
    "    \"\"\"Apply Gaussian blur using GPU.\"\"\"\n",
    "    if device.type != \"cuda\":\n",
    "        # Fall back to CPU if GPU not available\n",
    "        return gaussian_blur_cpu(img_tensor, kernel_size, sigma)\n",
    "    \n",
    "    # Move tensor to GPU\n",
    "    img_gpu = img_tensor.to(device)\n",
    "    \n",
    "    # Create Gaussian kernel\n",
    "    x = torch.arange(-(kernel_size // 2), kernel_size // 2 + 1, dtype=torch.float32, device=device)\n",
    "    kernel_1d = torch.exp(-x**2 / (2 * sigma**2))\n",
    "    kernel_1d = kernel_1d / kernel_1d.sum()\n",
    "    \n",
    "    # Create 2D kernel\n",
    "    kernel_2d = torch.outer(kernel_1d, kernel_1d).to(device)\n",
    "    kernel_2d = kernel_2d.view(1, 1, kernel_size, kernel_size)\n",
    "    kernel_2d = kernel_2d.repeat(3, 1, 1, 1)  # One kernel per channel\n",
    "    \n",
    "    # Prepare input for convolution\n",
    "    img_gpu = img_gpu.unsqueeze(0)  # Add batch dimension\n",
    "    \n",
    "    # Apply convolution\n",
    "    start_time = time.time()\n",
    "    padding = kernel_size // 2\n",
    "    blurred = torch.nn.functional.conv2d(\n",
    "        img_gpu, kernel_2d, padding=padding, groups=3\n",
    "    )\n",
    "    torch.cuda.synchronize()  # Ensure GPU operations complete\n",
    "    gpu_time = time.time() - start_time\n",
    "    \n",
    "    # Move result back to CPU\n",
    "    result = blurred.squeeze(0).cpu()\n",
    "    \n",
    "    return result, gpu_time\n",
    "\n",
    "# Apply Gaussian blur\n",
    "print(\"\\nApplying Gaussian Blur...\")\n",
    "cpu_blur, cpu_time = gaussian_blur_cpu(img_tensor)\n",
    "gpu_blur, gpu_time = gaussian_blur_gpu(img_tensor)\n",
    "print(f\"  CPU time: {cpu_time:.4f} seconds\")\n",
    "print(f\"  GPU time: {gpu_time:.4f} seconds\")\n",
    "if device.type == \"cuda\":\n",
    "    print(f\"  Speedup: {cpu_time/gpu_time:.2f}x\")\n",
    "\n",
    "# Display results\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Convert tensors to numpy for display\n",
    "original_np = img_tensor.permute(1, 2, 0).numpy()\n",
    "cpu_blur_np = cpu_blur.permute(1, 2, 0).numpy()\n",
    "gpu_blur_np = gpu_blur.permute(1, 2, 0).numpy()\n",
    "\n",
    "# Display images\n",
    "axes[0].imshow(original_np)\n",
    "axes[0].set_title(\"Original\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(cpu_blur_np)\n",
    "axes[1].set_title(f\"CPU Blur: {cpu_time:.4f}s\")\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(gpu_blur_np)\n",
    "axes[2].set_title(f\"GPU Blur: {gpu_time:.4f}s\")\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.suptitle(f\"Gaussian Blur - Speedup: {cpu_time/gpu_time:.2f}x\" if device.type == \"cuda\" else \"Gaussian Blur\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sobel Edge Detection\n",
    "\n",
    "Now let's implement Sobel edge detection on both CPU and GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def sobel_edge_detection_cpu(img_tensor):\n",
    "    \"\"\"Apply Sobel edge detection using CPU.\"\"\"\n",
    "    # Convert to numpy for OpenCV\n",
    "    img_np = (img_tensor.permute(1, 2, 0).numpy() * 255.0).astype(np.uint8)\n",
    "    img_gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Apply Sobel operators\n",
    "    sobel_x = cv2.Sobel(img_gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobel_y = cv2.Sobel(img_gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    \n",
    "    # Compute magnitude\n",
    "    magnitude = np.sqrt(sobel_x**2 + sobel_y**2)\n",
    "    \n",
    "    # Normalize\n",
    "    magnitude = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "    \n",
    "    cpu_time = time.time() - start_time\n",
    "    \n",
    "    # Convert back to tensor (single channel)\n",
    "    result = torch.from_numpy(magnitude).float().unsqueeze(0) / 255.0\n",
    "    \n",
    "    return result, cpu_time\n",
    "\n",
    "def sobel_edge_detection_gpu(img_tensor):\n",
    "    \"\"\"Apply Sobel edge detection using GPU.\"\"\"\n",
    "    if device.type != \"cuda\":\n",
    "        # Fall back to CPU if GPU not available\n",
    "        return sobel_edge_detection_cpu(img_tensor)\n",
    "    \n",
    "    # Move tensor to GPU\n",
    "    img_gpu = img_tensor.to(device)\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray_weights = torch.tensor([0.299, 0.587, 0.114], device=device).view(1, 3, 1, 1)\n",
    "    img_gpu = img_gpu.unsqueeze(0)  # Add batch dimension\n",
    "    img_gray = torch.sum(img_gpu * gray_weights, dim=1, keepdim=True)\n",
    "    \n",
    "    # Define Sobel kernels\n",
    "    sobel_x = torch.tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=torch.float32, device=device)\n",
    "    sobel_y = torch.tensor([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], dtype=torch.float32, device=device)\n",
    "    \n",
    "    sobel_x = sobel_x.view(1, 1, 3, 3)\n",
    "    sobel_y = sobel_y.view(1, 1, 3, 3)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Apply convolution\n",
    "    grad_x = torch.nn.functional.conv2d(img_gray, sobel_x, padding=1)\n",
    "    grad_y = torch.nn.functional.conv2d(img_gray, sobel_y, padding=1)\n",
    "    \n",
    "    # Compute magnitude\n",
    "    magnitude = torch.sqrt(grad_x**2 + grad_y**2)\n",
    "    \n",
    "    # Normalize\n",
    "    magnitude = magnitude / magnitude.max()\n",
    "    \n",
    "    torch.cuda.synchronize()  # Ensure GPU operations complete\n",
    "    gpu_time = time.time() - start_time\n",
    "    \n",
    "    # Move result back to CPU\n",
    "    result = magnitude.squeeze(0).cpu()\n",
    "    \n",
    "    return result, gpu_time\n",
    "\n",
    "# Apply Sobel edge detection\n",
    "print(\"\\nApplying Sobel Edge Detection...\")\n",
    "cpu_edge, cpu_time = sobel_edge_detection_cpu(img_tensor)\n",
    "gpu_edge, gpu_time = sobel_edge_detection_gpu(img_tensor)\n",
    "print(f\"  CPU time: {cpu_time:.4f} seconds\")\n",
    "print(f\"  GPU time: {gpu_time:.4f} seconds\")\n",
    "if device.type == \"cuda\":\n",
    "    print(f\"  Speedup: {cpu_time/gpu_time:.2f}x\")\n",
    "\n",
    "# Display results\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Convert tensors to numpy for display\n",
    "original_np = img_tensor.permute(1, 2, 0).numpy()\n",
    "cpu_edge_np = cpu_edge.squeeze().numpy()\n",
    "gpu_edge_np = gpu_edge.squeeze().numpy()\n",
    "\n",
    "# Display images\n",
    "axes[0].imshow(original_np)\n",
    "axes[0].set_title(\"Original\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(cpu_edge_np, cmap='gray')\n",
    "axes[1].set_title(f\"CPU Edge Detection: {cpu_time:.4f}s\")\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(gpu_edge_np, cmap='gray')\n",
    "axes[2].set_title(f\"GPU Edge Detection: {gpu_time:.4f}s\")\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.suptitle(f\"Sobel Edge Detection - Speedup: {cpu_time/gpu_time:.2f}x\" if device.type == \"cuda\" else \"Sobel Edge Detection\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Image Resizing\n",
    "\n",
    "Finally, let's compare CPU and GPU performance for image resizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def image_resize_cpu(img_tensor, scale_factor=0.25):\n",
    "    \"\"\"Resize image using CPU.\"\"\"\n",
    "    # Convert to numpy for OpenCV\n",
    "    img_np = (img_tensor.permute(1, 2, 0).numpy() * 255.0).astype(np.uint8)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Resize image\n",
    "    h, w = img_np.shape[:2]\n",
    "    new_h, new_w = int(h * scale_factor), int(w * scale_factor)\n",
    "    resized = cv2.resize(img_np, (new_w, new_h), interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    cpu_time = time.time() - start_time\n",
    "    \n",
    "    # Convert back to tensor\n",
    "    result = torch.from_numpy(resized).float().permute(2, 0, 1) / 255.0\n",
    "    \n",
    "    return result, cpu_time\n",
    "\n",
    "def image_resize_gpu(img_tensor, scale_factor=0.25):\n",
    "    \"\"\"Resize image using GPU.\"\"\"\n",
    "    if device.type != \"cuda\":\n",
    "        # Fall back to CPU if GPU not available\n",
    "        return image_resize_cpu(img_tensor, scale_factor)\n",
    "    \n",
    "    # Move tensor to GPU\n",
    "    img_gpu = img_tensor.to(device)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Add batch dimension\n",
    "    img_gpu = img_gpu.unsqueeze(0)\n",
    "    \n",
    "    # Resize using PyTorch's interpolate function\n",
    "    resized = torch.nn.functional.interpolate(\n",
    "        img_gpu, \n",
    "        scale_factor=scale_factor, \n",
    "        mode='bicubic',\n",
    "        align_corners=False\n",
    "    )\n",
    "    \n",
    "    torch.cuda.synchronize()  # Ensure GPU operations complete\n",
    "    gpu_time = time.time() - start_time\n",
    "    \n",
    "    # Move result back to CPU\n",
    "    result = resized.squeeze(0).cpu()\n",
    "    \n",
    "    return result, gpu_time\n",
    "\n",
    "# Apply image resizing\n",
    "print(\"\\nPerforming Image Resizing...\")\n",
    "cpu_resize, cpu_time = image_resize_cpu(img_tensor, scale_factor=0.25)\n",
    "gpu_resize, gpu_time = image_resize_gpu(img_tensor, scale_factor=0.25)\n",
    "print(f\"  CPU time: {cpu_time:.4f} seconds\")\n",
    "print(f\"  GPU time: {gpu_time:.4f} seconds\")\n",
    "if device.type == \"cuda\":\n",
    "    print(f\"  Speedup: {cpu_time/gpu_time:.2f}x\")\n",
    "\n",
    "# Display results\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Convert tensors to numpy for display\n",
    "original_np = img_tensor.permute(1, 2, 0).numpy()\n",
    "cpu_resize_np = cpu_resize.permute(1, 2, 0).numpy()\n",
    "gpu_resize_np = gpu_resize.permute(1, 2, 0).numpy()\n",
    "\n",
    "# Display images\n",
    "axes[0].imshow(original_np)\n",
    "axes[0].set_title(f\"Original ({original_np.shape[1]}x{original_np.shape[0]})\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(cpu_resize_np)\n",
    "axes[1].set_title(f\"CPU Resize: {cpu_time:.4f}s ({cpu_resize_np.shape[1]}x{cpu_resize_np.shape[0]})\")\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(gpu_resize_np)\n",
    "axes[2].set_title(f\"GPU Resize: {gpu_time:.4f}s ({gpu_resize_np.shape[1]}x{gpu_resize_np.shape[0]})\")\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.suptitle(f\"Image Resizing - Speedup: {cpu_time/gpu_time:.2f}x\" if device.type == \"cuda\" else \"Image Resizing\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Summary\n",
    "\n",
    "Let's summarize the performance improvements we observed with GPU acceleration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "print_separator()\n",
    "print(\"IMAGE PROCESSING PERFORMANCE SUMMARY\")\n",
    "print_separator()\n",
    "\n",
    "# Create a summary table\n",
    "operations = [\"Gaussian Blur\", \"Edge Detection\", \"Image Resizing\"]\n",
    "cpu_times = [cpu_time_blur, cpu_time_edge, cpu_time_resize]\n",
    "gpu_times = [gpu_time_blur, gpu_time_edge, gpu_time_resize]\n",
    "\n",
    "# Calculate speedups\n",
    "if device.type == \"cuda\":\n",
    "    speedups = [cpu/gpu for cpu, gpu in zip(cpu_times, gpu_times)]\n",
    "    avg_speedup = sum(speedups) / len(speedups)\n",
    "    \n",
    "    # Create a bar chart\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bar_width = 0.35\n",
    "    index = np.arange(len(operations))\n",
    "    \n",
    "    plt.bar(index - bar_width/2, cpu_times, bar_width, label='CPU', color='blue')\n",
    "    plt.bar(index + bar_width/2, gpu_times, bar_width, label='GPU', color='green')\n",
    "    \n",
    "    # Add speedup text\n",
    "    for i, speedup in enumerate(speedups):\n",
    "        plt.text(i, max(cpu_times[i], gpu_times[i]) + 0.01, f'{speedup:.1f}x', \n",
    "                 ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.xlabel('Operation')\n",
    "    plt.ylabel('Time (seconds)')\n",
    "    plt.title('CPU vs GPU Performance for Image Processing')\n",
    "    plt.xticks(index, operations)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Average speedup across all operations: {avg_speedup:.2f}x\")\n",
    "    print(\"\\nObservations:\")\n",
    "    print(f\"  • Gaussian Blur: {speedups[0]:.2f}x speedup\")\n",
    "    print(f\"  • Edge Detection: {speedups[1]:.2f}x speedup\")\n",
    "    print(f\"  • Image Resizing: {speedups[2]:.2f}x speedup\")\n",
    "    print(\"\\nGPU acceleration is particularly effective for:\")\n",
    "    print(\"  • Operations that can be parallelized (like convolutions)\")\n",
    "    print(\"  • Processing larger images\")\n",
    "    print(\"  • Batch processing multiple images\")\n",
    "else:\n",
    "    print(\"No GPU was available for this benchmark.\")\n",
    "    print(\"To see the benefits of GPU acceleration:\")\n",
    "    print(\"  1. Go to Runtime > Change runtime type\")\n",
    "    print(\"  2. Select 'GPU' under Hardware accelerator\")\n",
    "    print(\"  3. Click 'Save' and run this notebook again\")\n",
    "    print(\"\\nWith a GPU, you would typically see:\")\n",
    "    print(\"  • 5-20x speedup for Gaussian blur\")\n",
    "    print(\"  • 10-30x speedup for edge detection\")\n",
    "    print(\"  • 3-15x speedup for image resizing\")\n",
    "\n",
    "print_separator()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
